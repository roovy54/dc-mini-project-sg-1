{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "An8SDxsK_3UB",
        "outputId": "7207a27c-9d66-4b84-eb51-6cc9dbaead1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['data.zip']\n",
            "Archive:  data.zip\n",
            "replace data/eng-fra.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "from io import open\n",
        "import glob\n",
        "import os\n",
        "\n",
        "def findFiles(path): return glob.glob(path)  #The findFiles function uses glob.glob to find files matching a specified pattern.\n",
        "\n",
        "print(findFiles('data.zip'))\n",
        "!unzip data.zip\n",
        "\n",
        "import unicodedata\n",
        "import string\n",
        "\n",
        "all_letters = string.ascii_letters + \" .,;'\"\n",
        "n_letters = len(all_letters)\n",
        "\n",
        "def unicodeToAscii(s):   #The unicodeToAscii function converts Unicode strings to ASCII, removing diacritics and non-ASCII characters.\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s) #Normalization form decomposition\n",
        "        if unicodedata.category(c) != 'Mn' #The list comprehension filters out characters that are diacritical marks\n",
        "        and c in all_letters\n",
        "    )\n",
        "\n",
        "print(unicodeToAscii('Ślusàrski'))\n",
        "\n",
        "# Build the category_lines dictionary, a list of names per language\n",
        "category_lines = {}\n",
        "all_categories = []\n",
        "\n",
        "# Read a file and split into lines\n",
        "def readLines(filename):\n",
        "    lines = open(filename, encoding='utf-8').read().strip().split('\\n') #The file is opened with UTF-8 encoding, read into a single string, stripped of leading and trailing whitespace, and split into lines.\n",
        "    return [unicodeToAscii(line) for line in lines]  #returns the lines in ASCII format.\n",
        "\n",
        "for filename in findFiles('data/names/*.txt'):\n",
        "    category = os.path.splitext(os.path.basename(filename))[0]\n",
        "    all_categories.append(category)\n",
        "    lines = readLines(filename)\n",
        "    category_lines[category] = lines\n",
        "\n",
        "n_categories = len(all_categories)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_categories"
      ],
      "metadata": {
        "id": "Z7YMl5DsdX46"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "category_lines"
      ],
      "metadata": {
        "id": "bOl6zx5YdeN7",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(category_lines['Italian'][:5])\n"
      ],
      "metadata": {
        "id": "fhkleqjBAuZk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(all_letters))"
      ],
      "metadata": {
        "id": "erq_JgzThPQ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Find letter index from all_letters, e.g. \"a\" = 0\n",
        "def letterToIndex(letter):\n",
        "    return all_letters.find(letter)\n",
        "\n",
        "# Just for demonstration, turn a letter into a <1 x n_letters> Tensor\n",
        "def letterToTensor(letter):\n",
        "    tensor = torch.zeros(1, n_letters)\n",
        "    tensor[0][letterToIndex(letter)] = 1\n",
        "    return tensor\n",
        "\n",
        "# Turn a line into a <line_length x 1 x n_letters>,\n",
        "# or an array of one-hot letter vectors\n",
        "def lineToTensor(line):\n",
        "    tensor = torch.zeros(len(line), 1, n_letters)\n",
        "    for li, letter in enumerate(line):\n",
        "        tensor[li][0][letterToIndex(letter)] = 1\n",
        "    return tensor\n",
        "\n",
        "print(letterToTensor('J'))\n",
        "\n",
        "print(lineToTensor('Jones').size())"
      ],
      "metadata": {
        "id": "KgCNQUHjvu1N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class RNN(nn.Module):\n",
        "\n",
        "  def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(RNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.W_ih = nn.Parameter(torch.randn(hidden_size, input_size))\n",
        "        self.W_hh = nn.Parameter(torch.randn(hidden_size, hidden_size))\n",
        "        self.W_ho = nn.Parameter(torch.randn(output_size, hidden_size))\n",
        "        self.b_h = nn.Parameter(torch.zeros(hidden_size))\n",
        "        self.b_o = nn.Parameter(torch.zeros(output_size))\n",
        "\n",
        "  def forward(self, input, hidden,time_steps=10):\n",
        "        # Ensure input and hidden are tensors\n",
        "        if not torch.is_tensor(input) or not torch.is_tensor(hidden):\n",
        "            raise ValueError(\"Input and hidden must be tensors\")\n",
        "\n",
        "        # Adjust shapes for matrix multiplication\n",
        "        input = input.view(-1, self.W_ih.size(1))  # Ensure input is (hidden_size, input_size)\n",
        "        #hidden = hidden.view(-1, self.W_hh.size(1))  # Ensure hidden is (hidden_size, hidden_size)\n",
        "\n",
        "        # Smiti\n",
        "        W_hh_0 = torch.zeros(self.hidden_size, self.hidden_size)\n",
        "        h_t_plus_1 = W_hh_0\n",
        "\n",
        "        for t in range(time_steps):\n",
        "          #  sum_W_hh_h = torch.zeros(self.hidden_size)\n",
        "          #  for k in range(t+1):\n",
        "          #      sum_W_hh_h += torch.matmul(self.W_hh ** (k+1), h[t-k])  # Summation part 1: W_hh^{k+1} * h_{t-k}\n",
        "          #  sum_b= torch.zeros(self.hidden_size)\n",
        "          #  sum_W_hh_x = torch.zeros(self.hidden_size)\n",
        "          #  for k in range(t+1):\n",
        "          #      sum_W_hh_x += torch.matmul(self.W_hh ** k, x[t-k])   # Summation part 2: W_hh^k * x_{t-k} + W_hh^k * b_{t-k}\n",
        "          #      sum_b += torch.matmul(W_hh ** k, b[t-k])\n",
        "          #  h_t_plus_1 = sum_W_hh_h + torch.matmul(self.W_ho, sum_W_hh_x) + sum_b # Combining both parts\n",
        "        # Perform matrix multiplications\n",
        "          rnn_linear = torch.tanh(torch.matmul(input, self.W_ih.t()) + torch.matmul(h_t_plus_1, self.W_hh.t()) + self.b_h)\n",
        "          # z=torch.LeakyReLU(rnn_linear)\n",
        "          z = rnn_linear\n",
        "          output = torch.softmax((torch.matmul(z, self.W_ho.t()) + self.b_o), dim=1)\n",
        "\n",
        "          h_t_plus_1 = rnn_linear\n",
        "\n",
        "\n",
        "        return output, rnn_linear\n",
        "\n"
      ],
      "metadata": {
        "id": "rrFJp1cryylL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = letterToTensor('A')\n",
        "print(len(input[0]))\n",
        "n_hidden = 1\n",
        "hidden = torch.zeros(1, n_hidden)\n",
        "\n",
        "\n",
        "rnn = RNN(57, n_hidden, 18)\n",
        "print(rnn)"
      ],
      "metadata": {
        "id": "p2wSr-Fdy6wc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = lineToTensor('Albert')\n",
        "hidden = torch.zeros(1, n_hidden)\n",
        "\n",
        "output, next_hidden = rnn(input[0], hidden)\n",
        "print(output)"
      ],
      "metadata": {
        "id": "haApTgUly-xL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def categoryFromOutput(output):\n",
        "    # Get the top category index from the model's output\n",
        "    top_n, top_i = output.topk(1)  # Returns the highest value and its index\n",
        "    category_i = top_i[0].item()   # Convert the top index tensor to a Python integer\n",
        "    return all_categories[category_i], category_i  # Return the category name and its index\n",
        "\n",
        "# Example usage: print the category name and index for the given output\n",
        "print(categoryFromOutput(output))\n"
      ],
      "metadata": {
        "id": "HlTT7X_mzEaD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "# Function to choose a random element from a list ``l``\n",
        "def randomChoice(l):\n",
        "    return l[random.randint(0, len(l) - 1)]\n",
        "\n",
        "# Function to create a random training example\n",
        "def randomTrainingExample():\n",
        "    # Choose a random category (language)\n",
        "    category = randomChoice(all_categories)\n",
        "\n",
        "    # Choose a random line (name) from the chosen category\n",
        "    line = randomChoice(category_lines[category])\n",
        "\n",
        "    # Create a tensor for the category (as an index in all_categories)\n",
        "    category_tensor = torch.tensor([all_categories.index(category)], dtype=torch.long)\n",
        "\n",
        "    # Convert the line to a tensor using the lineToTensor function\n",
        "    line_tensor = lineToTensor(line)\n",
        "\n",
        "    # Return the category, line, and their respective tensors\n",
        "    return category, line, category_tensor, line_tensor\n",
        "\n",
        "# Loop to print 10 random training examples\n",
        "for i in range(10):\n",
        "    # Get a random training example\n",
        "    category, line, category_tensor, line_tensor = randomTrainingExample()\n",
        "\n",
        "    # Print the category and line\n",
        "    print('category =', category, '/ line =', line)\n"
      ],
      "metadata": {
        "id": "h53SvYf5zJBL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.NLLLoss()"
      ],
      "metadata": {
        "id": "8MdNPCqczMDz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.005 # If you set this too high, it might explode. If too low, it might not learn\n",
        "\n",
        "def train(category_tensor, line_tensor):\n",
        "    # hidden = rnn.initHidden()\n",
        "    n_hidden = 1\n",
        "    hidden = torch.zeros(1, n_hidden)\n",
        "\n",
        "    rnn.zero_grad()\n",
        "\n",
        "    for i in range(line_tensor.size()[0]):\n",
        "        output, hidden = rnn(line_tensor[i], hidden)\n",
        "\n",
        "    loss = criterion(output, category_tensor)\n",
        "    loss.backward()\n",
        "\n",
        "    # Add parameters' gradients to their values, multiplied by learning rate (this is done instead of optimizer.step())\n",
        "    for p in rnn.parameters():\n",
        "        p.data.add_(p.grad.data, alpha=-learning_rate)\n",
        "\n",
        "    return output, loss.item()"
      ],
      "metadata": {
        "id": "R8Bwv87FzN0r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "# Number of iterations to train\n",
        "n_iters = 100000\n",
        "\n",
        "# Print progress every ``print_every`` iterations\n",
        "print_every = 5000\n",
        "\n",
        "# Record loss for plotting every ``plot_every`` iterations\n",
        "plot_every = 1000\n",
        "\n",
        "# Keep track of losses for plotting\n",
        "current_loss = 0\n",
        "all_losses = []\n",
        "\n",
        "# Function to calculate the elapsed time since ``since`` in minutes and seconds\n",
        "def timeSince(since):\n",
        "    now = time.time()  # Current time\n",
        "    s = now - since  # Elapsed time in seconds\n",
        "    m = math.floor(s / 60)  # Convert seconds to minutes\n",
        "    s -= m * 60  # Remaining seconds after converting to minutes\n",
        "    return '%dm %ds' % (m, s)  # Format as \"Xm Ys\"\n",
        "\n",
        "start = time.time()  # Record the start time\n",
        "\n",
        "for iter in range(1, n_iters + 1):\n",
        "    # Get a random training example: category, line, and their tensor representations\n",
        "    category, line, category_tensor, line_tensor = randomTrainingExample()\n",
        "\n",
        "    # Train the model on the example and get the output and loss\n",
        "    output, loss = train(category_tensor, line_tensor)\n",
        "\n",
        "    current_loss += loss  # Accumulate the loss\n",
        "\n",
        "    # Print ``iter`` number, loss, name and guess every ``print_every`` iterations\n",
        "    if iter % print_every == 0:\n",
        "        # Get the model's guess and the index of the guessed category\n",
        "        guess, guess_i = categoryFromOutput(output)\n",
        "\n",
        "        # Check if the guess is correct\n",
        "        correct = '✓' if guess == category else '✗ (%s)' % category\n",
        "\n",
        "        # Print iteration number, progress, elapsed time, loss, input line, guessed category, and correctness\n",
        "        print('%d %d%% (%s) %.4f %s / %s %s' % (\n",
        "            iter, iter / n_iters * 100, timeSince(start), loss, line, guess, correct))\n",
        "\n",
        "    # Add current loss average to the list of losses every ``plot_every`` iterations\n",
        "    if iter % plot_every == 0:\n",
        "        all_losses.append(current_loss / plot_every)  # Average loss over the last ``plot_every`` iterations\n",
        "        current_loss = 0  # Reset current loss\n"
      ],
      "metadata": {
        "id": "RYW3nq9IzQDC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Keep track of correct guesses in a confusion matrix\n",
        "confusion = torch.zeros(n_categories, n_categories)  # Initialize an empty confusion matrix\n",
        "n_confusion = 10000  # Number of examples to evaluate for the confusion matrix\n",
        "\n",
        "import matplotlib.pyplot as plt  # Importing matplotlib for plotting\n",
        "import matplotlib.ticker as ticker  # Importing ticker for customizing ticks\n",
        "\n",
        "# Just return an output given a line\n",
        "def evaluate(line_tensor):\n",
        "    # hidden = rnn.initHidden()  # Initialize the hidden state\n",
        "    n_hidden = 1\n",
        "    hidden = torch.zeros(1, n_hidden)\n",
        "\n",
        "\n",
        "    for i in range(line_tensor.size()[0]):\n",
        "        output, hidden = rnn(line_tensor[i], hidden)  # Pass each character in the line through the RNN\n",
        "\n",
        "    return output  # Return the final output of the RNN\n",
        "\n",
        "# Go through a bunch of examples and record which are correctly guessed\n",
        "for i in range(n_confusion):\n",
        "    category, line, category_tensor, line_tensor = randomTrainingExample()  # Get a random training example\n",
        "    output = evaluate(line_tensor)  # Evaluate the line tensor\n",
        "    guess, guess_i = categoryFromOutput(output)  # Get the guessed category and its index\n",
        "    category_i = all_categories.index(category)  # Get the true category index\n",
        "    confusion[category_i][guess_i] += 1  # Increment the corresponding cell in the confusion matrix\n",
        "\n",
        "# Normalize by dividing every row by its sum\n",
        "for i in range(n_categories):\n",
        "    confusion[i] = confusion[i] / confusion[i].sum()  # Normalize each row\n",
        "\n",
        "# Set up plot\n",
        "fig = plt.figure()  # Create a new figure\n",
        "ax = fig.add_subplot(111)  # Add a subplot to the figure\n",
        "cax = ax.matshow(confusion.numpy())  # Display the confusion matrix as an image\n",
        "fig.colorbar(cax)  # Add a color bar to the figure\n",
        "\n",
        "# Set up axes\n",
        "ax.set_xticklabels([''] + all_categories, rotation=90)  # Set x-axis labels with rotation\n",
        "ax.set_yticklabels([''] + all_categories)  # Set y-axis labels\n",
        "\n",
        "# Force label at every tick\n",
        "ax.xaxis.set_major_locator(ticker.MultipleLocator(1))  # Set x-axis major ticks\n",
        "ax.yaxis.set_major_locator(ticker.MultipleLocator(1))  # Set y-axis major ticks\n",
        "plt.show()  # Show the plot"
      ],
      "metadata": {
        "id": "Wgrn-oKkzh9j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(input_line, n_predictions=3):\n",
        "    print('\\n> %s' % input_line)\n",
        "    with torch.no_grad():\n",
        "        output = evaluate(lineToTensor(input_line))\n",
        "\n",
        "        # Get top N categories\n",
        "        topv, topi = output.topk(n_predictions, 1, True)\n",
        "        predictions = []\n",
        "\n",
        "        for i in range(n_predictions):\n",
        "            value = topv[0][i].item()\n",
        "            category_index = topi[0][i].item()\n",
        "            print('(%.2f) %s' % (value, all_categories[category_index]))\n",
        "            predictions.append([value, all_categories[category_index]])\n"
      ],
      "metadata": {
        "id": "CIkk_crjPwAe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict('Dovesky')\n",
        "predict('Jackson')\n",
        "predict('Satoshi')"
      ],
      "metadata": {
        "id": "-PrDqjqK-5EQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Pt6CXQtVnQXy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}