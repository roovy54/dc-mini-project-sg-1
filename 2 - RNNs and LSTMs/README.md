# Week 2: DC Mini Project - RNNs from Scratch

## Task 2.1: Understanding RNNs, LSTMs, GRUs, and Encoder-Decoder Models

### Resources:
1. **RNNs by StatQuest**: [Watch Video](https://youtu.be/AsNTP8Kwu80?feature=shared)
2. **Theory Understanding**:
   - [NLP with Deep Learning: Neural Networks, RNNs, LSTMs, and GRUs](https://medium.com/@mervebdurna/nlp-with-deep-learning-neural-networks-rnns-lstms-and-gru-3de7289bb4f8)
   - [Recurrent Neural Networks (RNN, LSTM, GRU)](https://batchuvamsi.medium.com/recurrent-neural-networks-rnn-lstm-gru-dd630fd8ae46)

---

## Task 2.2: Implementing RNNs in Code

### Notebooks:
1. **Sunspots**: [Open in Colab](https://colab.research.google.com/drive/1eYPhkygpXV9iSVyh47zt8MdROXMYO7pD?usp=sharing)
2. **Name-Language**: [Open in Colab](https://colab.research.google.com/drive/1drC5hiF41aipIzzncjJIT0Fjv5LCbajs?usp=sharing)

### Instructions:
- Review the **Sunspots** notebook to understand how the RNN model architecture is implemented.
- Use this understanding to complete the blank code block in the **Name-Language** notebook.
- You can use any method to implement the model, but **PyTorch** is preferred.
- Feel free to experiment with different architectures if you like.

### Bonus:
- Implement an **LSTM** in either of the two notebooks.
- The first person to successfully implement an LSTM will receive a treat from Harshith at HFC!

### Note:
- Focus on the model architecture. While understanding data preprocessing is beneficial, it is not mandatory.
- Post any doubts or questions in the group for assistance.

